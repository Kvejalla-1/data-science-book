{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 Ensemble Methods\n",
    "\n",
    "Suppose we have two prediction models $f_1$ and $f_2$. Can we combine the two models to produce an even better prediction model? Ensemble methods are ways of combining two or more prediction models.\n",
    "\n",
    "First, let's fit two simple models (a linear regression model and a $50$-nearest neighbors model) so that we can combine them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsregressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=50, p=2,\n",
       "          weights='uniform'))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "housing_df = pd.read_csv(\"https://raw.githubusercontent.com/dlsun/data-science-book/master/data/AmesHousing.txt\",\n",
    "                         sep=\"\\t\")\n",
    "X_train, y_train = housing_df[[\"Gr Liv Area\"]].astype(float), housing_df[\"SalePrice\"]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model2 = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=50))\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to combine 2 two prediction models is to take a weighted average \n",
    "\n",
    "$$ f({\\bf x}) = \\text{weight}_1 \\cdot f_1({\\bf x}) + \\text{weight}_2 \\cdot f_2({\\bf x}) $$\n",
    "\n",
    "or more generally, if we have $M$ models,\n",
    "\n",
    "$$ f({\\bf x}) = \\text{weight}_1 \\cdot f_1({\\bf x}) + \\text{weight}_2 \\cdot f_2({\\bf x}) + ... + \\text{weight}_M \\cdot f_M({\\bf x}).$$\n",
    "\n",
    "We could choose these weights arbitrarily. For example, in the absence of any information about the models, we should give equal weight to the predictions to each of the models, so one common choice for the weights is $1 / M$, in which case we simply average the predictions from the $M$ models.\n",
    "\n",
    "So one way to combine predictions from the two models we fit above is to average them. For example, if we were trying to obtain predictions for a grid of $x$ values from 0 to 6000, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 44099.81718238,  44155.66418281,  44211.51118324, ...,\n",
       "       524325.91875449, 524381.76575492, 524437.61275535])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = pd.Series(\n",
    "    data=np.arange(6000.),\n",
    "    index=np.arange(6000.)\n",
    ")\n",
    "X_new = x_new.to_frame()\n",
    "\n",
    "(model1.predict(X_new) + model2.predict(X_new)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we may be able to do better. We can learn the weights from data. Notice how the weights are essentially the \"coefficients\" in a linear regression model. We can calculate the predictions from each model on the training data and fit another linear regression model on top of these predictions to predict the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0721527 , 0.92908732])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions = pd.DataFrame({\n",
    "    \"linear\": model1.predict(X_train),\n",
    "    \"knn\": model2.predict(X_train)\n",
    "})\n",
    "\n",
    "ensembler = LinearRegression(fit_intercept=False)\n",
    "ensembler.fit(model_predictions, y_train)\n",
    "ensembler.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it appears that the optimal weights are $0.072$ and $0.929$. The $k$-nearest neighbors model gets much more weight than the linear regression model. Note that we did not constrain these weights to add up to 1, but it turns out that their sum comes out to be close to 1 anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating an Ensemble Model\n",
    "\n",
    "How do we determine whether the ensemble model is better than the individual models? We use cross validation. But implementing $k$-fold cross validation is a bit tricky. For each fold, we need to refit each individual model in the ensemble, as well as the linear regression on top of the individual models' predictions. To do this, we will define a custom \"model\", or as _scikit-learn_ calls it, an \"estimator\". This estimator will carry out all of the steps in fitting an ensemble model and obtaining predictions from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class RegressionEnsembler(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"Creates an ensemble model out of a collection of individual estimators\n",
    "    \n",
    "    Args:\n",
    "      estimators: A list containing the individual estimators.\n",
    "      learn_weights: A boolean that specifies whether we should learn the\n",
    "        \"optimal\" weights/coefficients to apply to each individual estimator's\n",
    "        predictions. If False, we simply return the straight average of the \n",
    "        individual estimators' predictions as the ensemble prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, estimators, learn_weights=True):\n",
    "        self.estimators = estimators\n",
    "        self.learn_weights = learn_weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # check that X and y have the correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # store the training features and the labels\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        # call the fit method of each of the estimators\n",
    "        for estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "            \n",
    "        # if we wish to learn the \"optimal\" weights from the training data\n",
    "        if self.learn_weights:\n",
    "            # get prediction from each estimator on the training data\n",
    "            predictions = []\n",
    "            for estimator in self.estimators:\n",
    "                predictions.append(estimator.predict(X))\n",
    "            Y_ = np.column_stack(predictions)\n",
    "        \n",
    "            # fit linear regression on top of the estimators' predictions\n",
    "            self.ensembler = LinearRegression(fit_intercept=False)\n",
    "            self.ensembler.fit(Y_, y)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # check that fit has been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        \n",
    "        # check that X has the right form\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # calculate predictions from the estimators\n",
    "        predictions = []\n",
    "        for estimator in self.estimators:\n",
    "            predictions.append(estimator.predict(X))\n",
    "        Y_ = np.column_stack(predictions)\n",
    "        \n",
    "        # return predictions\n",
    "        if self.learn_weights:\n",
    "            return self.ensembler.predict(Y_)\n",
    "        else:\n",
    "            return Y_.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the `RegressionEnsembler` we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([202489.90647013, 119600.7137348 , 162412.81411257, ...,\n",
       "       120893.74835977, 160278.6520541 , 244227.18514808])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model = RegressionEnsembler([model1, model2])\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "ensemble_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `RegressionEnsembler` is something we can pass to `cross_val_score` to get validation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3288114309.4176197,\n",
       " 3274247814.1959844,\n",
       " 3247240758.8164835,\n",
       " 3316542363.5205145)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "(\n",
    "    -cross_val_score(model1, X_train, y_train,\n",
    "                     cv=20, scoring=\"neg_mean_squared_error\").mean(),\n",
    "    -cross_val_score(model2, X_train, y_train,\n",
    "                     cv=20, scoring=\"neg_mean_squared_error\").mean(),\n",
    "    -cross_val_score(RegressionEnsembler([model1, model2], learn_weights=False), X_train, y_train,\n",
    "                     cv=20, scoring=\"neg_mean_squared_error\").mean(),\n",
    "    -cross_val_score(RegressionEnsembler([model1, model2], learn_weights=True), X_train, y_train,\n",
    "                     cv=20, scoring=\"neg_mean_squared_error\").mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that ensembling helps on this data set, but not if we try to learn the weights from the data. It is actually better to take a straight average than to try to learn the optimal weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
